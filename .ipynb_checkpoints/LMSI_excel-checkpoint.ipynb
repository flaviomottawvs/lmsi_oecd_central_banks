{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c1b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f66c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566db5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e26ab78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f8001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb195c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d912ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57380ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8708787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a625abb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65573721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ae91017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/flaviomotta/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/flaviomotta/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Russia/2013-09-13.pdf saved to: /Users/flaviomotta/UCP_PROJETO/Global_analysis.xlsx\n",
      "Results for Russia/2013-10-14.pdf saved to: /Users/flaviomotta/UCP_PROJETO/Global_analysis.xlsx\n",
      "Results for Russia/2013-11-08.pdf saved to: /Users/flaviomotta/UCP_PROJETO/Global_analysis.xlsx\n",
      "Results for Russia/2013-12-13.pdf saved to: /Users/flaviomotta/UCP_PROJETO/Global_analysis.xlsx\n",
      "Results for Russia/2014-02-14.pdf saved to: /Users/flaviomotta/UCP_PROJETO/Global_analysis.xlsx\n",
      "Results for Russia/2014-03-03.pdf saved to: /Users/flaviomotta/UCP_PROJETO/Global_analysis.xlsx\n",
      "Results for Russia/2014-03-14.pdf saved to: /Users/flaviomotta/UCP_PROJETO/Global_analysis.xlsx\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, filename)\n\u001b[1;32m     74\u001b[0m text \u001b[38;5;241m=\u001b[39m extract_text(file_path)\n\u001b[0;32m---> 75\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msentiment_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloughran_mcdonald_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m word_count, sent_count, syllable_count \u001b[38;5;241m=\u001b[39m count_words_sents_syllables(text)\n\u001b[1;32m     77\u001b[0m fki_value \u001b[38;5;241m=\u001b[39m calculate_fki(word_count, sent_count, syllable_count)\n",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m, in \u001b[0;36msentiment_analysis\u001b[0;34m(text, dictionary)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;129;01min\u001b[39;00m dictionary[word_column]\u001b[38;5;241m.\u001b[39mvalues:\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m category_columns:\n\u001b[0;32m---> 32\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m dictionary\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdictionary\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword_column\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, category]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     33\u001b[0m                 results[category] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PYTHON_3/lib/python3.8/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PYTHON_3/lib/python3.8/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PYTHON_3/lib/python3.8/site-packages/pandas/core/series.py:6096\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6093\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6095\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6096\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PYTHON_3/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:293\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PYTHON_3/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:82\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## VERSAO FINAL , GERA TODOS EM UM MESMO ARQUIVO E JÁ ORDENADOS \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from openpyxl import Workbook, load_workbook\n",
    "from pdfminer.high_level import extract_text\n",
    "import pyphen\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# Inicializando variáveis e downloads necessários\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "url = 'https://drive.google.com/u/0/uc?id=17CmUZM9hGUdGYjCXcjQLyybjTrcjrhik&export=download'\n",
    "loughran_mcdonald_dict = pd.read_csv(url)\n",
    "\n",
    "word_column = 'Word'\n",
    "category_columns = ['Negative', 'Positive', 'Uncertainty', 'Litigious', 'Constraining', 'Strong_Modal', 'Weak_Modal', 'Syllables']\n",
    "\n",
    "dic = pyphen.Pyphen(lang='en')\n",
    "\n",
    "def sentiment_analysis(text, dictionary):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if not word.lower() in stopwords.words('english')]\n",
    "    results = {category: 0 for category in category_columns}\n",
    "    for word in tokens:\n",
    "        if word.upper() in dictionary[word_column].values:\n",
    "            for category in category_columns:\n",
    "                if dictionary.loc[dictionary[word_column] == word.upper(), category].values[0] > 0:\n",
    "                    results[category] += 1\n",
    "    return results\n",
    "\n",
    "def count_syllables(words):\n",
    "    return sum([len(dic.inserted(word).split('-')) for word in words])\n",
    "\n",
    "def count_words_sents_syllables(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    tokens = word_tokenize(text)\n",
    "    syllables = count_syllables(tokens)\n",
    "    return len(tokens), len(sentences), syllables\n",
    "\n",
    "def calculate_fki(word_count, sent_count, syllable_count):\n",
    "    try:\n",
    "        FKI = 0.39 * (word_count / sent_count) + 11.8 * (syllable_count / word_count) - 15.59\n",
    "        return FKI\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "\n",
    "countries_directory = r'/Users/flaviomotta/UCP_PROJETO/TODOS OS PAISES'\n",
    "excel_directory = r'/Users/flaviomotta/UCP_PROJETO'\n",
    "excel_file = r'Global_analysis.xlsx'\n",
    "excel_path = os.path.join(excel_directory, excel_file)\n",
    "\n",
    "# Carregando ou criando a planilha Excel\n",
    "try:\n",
    "    wb = load_workbook(excel_path)\n",
    "    ws = wb.active\n",
    "except FileNotFoundError:\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.append(['Country', 'Filename'] + category_columns + ['Word Count', 'Sentence Count', 'Syllable Count', 'LMSI', 'FKI'])\n",
    "\n",
    "processed_entries = [(ws['A' + str(row)].value, ws['B' + str(row)].value) for row in range(2, ws.max_row + 1)]\n",
    "\n",
    "for root, dirs, files in os.walk(countries_directory):\n",
    "    country_name = os.path.basename(root)\n",
    "    # Ordenando os arquivos antes do processamento\n",
    "    files = sorted([f for f in files if f.endswith('.pdf') and (country_name, f) not in processed_entries])\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(root, filename)\n",
    "        text = extract_text(file_path)\n",
    "        results = sentiment_analysis(text, loughran_mcdonald_dict)\n",
    "        word_count, sent_count, syllable_count = count_words_sents_syllables(text)\n",
    "        fki_value = calculate_fki(word_count, sent_count, syllable_count)\n",
    "        lmsi = results['Positive'] / (results['Positive'] + results['Negative']) if (results['Positive'] + results['Negative']) > 0 else 0\n",
    "        ws.append([country_name, filename] + [results[category] for category in category_columns] + [word_count, sent_count, syllable_count, lmsi, fki_value])\n",
    "        wb.save(excel_path)  # Salva após cada PDF ser processado\n",
    "        print(f\"Results for {country_name}/{filename} saved to: {excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf63dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
